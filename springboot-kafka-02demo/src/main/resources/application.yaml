spring:
  kafka:
      bootstrap-servers: localhost:9093
      producer:
        acks: 1 # 0-不应答 1-只有leader节点应答  all：leader节点和所有的follower节点共同应答
        retries: 3 #重试次数
        key-serializer: org.apache.kafka.common.serialization.StringSerializer # 消费者 key 的序列化
        value-serializer: org.springframework.kafka.support.serializer.JsonSerializer # 消费者 value 的序列化
        batch-size: 16384 # 每次批量发送消息的最大数量
        buffer-memory: 33554432 # 每次批量发送消息的最大数量
        properties:
          linger:
            ms: 30000 # 批处理延迟时间上限 这里配置为 30 * 1000 ms 过后
      consumer:
        auto-offset-reset: earliest
        key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
        value-deserializer: org.springframework.kafka.support.serializer.JsonDeserializer
        fetch-max-wait: 10000 #poll 一次拉取的阻塞的最长时长   单位：毫秒  这里指的时阻塞拉取需要满足至少 fetch-min-size 大小的消息
        fetch-min-size: 10 #poll 一次消费拉取的最小数据量，单位：字节
        max-poll-records: 100 #poll 一次消费拉取的最大数量
        properties:
          spring:
            json:
              trusted:
                packages: com.cunshan.springboot.lab02.kafkademo.message
      listener:
        type: BATCH #监听器类型，默认为 SINGLE：只监听单条消息  配置成 BATCH: 监听多条消息，批量消费
        missing-topics-fatal: false #消费监听接口监听的主题不存在时，默认会报错，所以通过设置为 false 解决报错
  logging:
    level:
      org:
        springframework:
          kafka: ERROR
        apache:
          kafka: ERROR